{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjvee6v9RYby2zoqf6yWsk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n",
        "\n",
        "Inspiration for this question comes from: [1](https://mubaris.com/posts/linear-regression/) and [2](http://vxy10.github.io/2016/06/25/lin-reg-matrix/).\n",
        "\n",
        "This is an implementation of the linear regression algorithm from scratch in Python. Linear regression maps feature vectors to a continuous value in the range $[-\\infty,+\\infty]$ by linearly combining the feature values. \n",
        "\n",
        "### Model Representation\n",
        "Data will be represented as a dataframe or feature matrix.\n",
        "\n",
        "Let our feature matrix be $X$ whose dimensions are $n \\times m$, $\\theta$ be a weight matrix of dimensions $m \\times 1$, the bias vector $b$ a column vector of dimension $n\\times 1$. Using these we can predict $\\hat{Y}$\n",
        "by the following relationship:\n",
        "\n",
        "$$\\hat{Y} = X\\theta + b$$ \n",
        "\n",
        "### Data: Facebook posts metrics\n",
        "\n",
        "This data contains features describing posts from a cosmetic brand's Facebook page. The authors use the following features: \n",
        "\n",
        "The dataset can be [found here](http://archive.ics.uci.edu/ml/datasets/Facebook+metrics). The authors of the dataset use the following features:\n",
        "\n",
        "* Category,\n",
        "* Page total likes: Number of people who have liked the company's page), \n",
        "* Type: Type of content (Link, Photo, Status, Video), \n",
        "* Post month: Month the post was published (January, February, March, …, December), \n",
        "* Post hour: Hour the post was published (0, 1, 2, 3, 4, …, 23) , \n",
        "* Post weekday: Weekday the post was published (Sunday, Monday, …,\n",
        "Saturday) , \n",
        "* Paid: If the company paid to Facebook for advertising (yes, no)\n",
        "\n",
        "to model: \n",
        "\n",
        "'Lifetime Post Total Reach', 'Lifetime Post Total Impressions', 'Lifetime Engaged Users', 'Lifetime Post Consumers',\n",
        "'Lifetime Post Consumptions', 'Lifetime Post Impressions by people who have liked your Page', 'Lifetime Post reach by people who like your Page', 'Lifetime People who have liked your Page and engaged with your post', 'comment', 'like', 'share', 'Total Interactions'.\n",
        "\n",
        "\n",
        "This model will focus on 'Total Interactions'. The feature space for this model will include: Category, Page total likes, Post month, Post hour, Post weekday, and Paid.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qrL_4sEr50VP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Data\n"
      ],
      "metadata": {
        "id": "KepUCOoj7gTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip -O ./Facebook_metrics.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile('./Facebook_metrics.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "relM8rmK7Obw",
        "outputId": "de7a2ef1-bb9b-47f8-9373-1e062992201e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-29 02:20:26--  http://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16281 (16K) [application/x-httpd-php]\n",
            "Saving to: ‘./Facebook_metrics.zip’\n",
            "\n",
            "./Facebook_metrics. 100%[===================>]  15.90K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-01-29 02:20:26 (249 KB/s) - ‘./Facebook_metrics.zip’ saved [16281/16281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Data"
      ],
      "metadata": {
        "id": "0mnq2g6m73bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Shuffles the data in place \n",
        "def shuffle_data(data):\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "# Normalizing all remaining columns\n",
        "def normalize_col(col):\n",
        "    return (col - col.min())/(col.max() - col.min())\n",
        "\n",
        "# Read in the data\n",
        "lr_dataframe = pd.read_csv('dataset_Facebook.csv',sep=';')\n",
        "lr_dataframe.dropna(inplace=True)\n",
        "columns_to_drop = ['Type','Lifetime Post Total Reach', 'Lifetime Post Total Impressions',\n",
        "       'Lifetime Engaged Users', 'Lifetime Post Consumers',\n",
        "       'Lifetime Post Consumptions',\n",
        "       'Lifetime Post Impressions by people who have liked your Page',\n",
        "       'Lifetime Post reach by people who like your Page',\n",
        "       'Lifetime People who have liked your Page and engaged with your post',\n",
        "       'comment', 'like', 'share']\n",
        "lr_dataframe.drop(columns=columns_to_drop,inplace=True)\n",
        "\n",
        "lr_dataframe = lr_dataframe.apply(normalize_col)\n",
        "\n",
        "# Get entries as a numpy array\n",
        "lr_data = lr_dataframe.values[:, :]\n",
        "\n",
        "# Shuffle once for reproducibility\n",
        "shuffle_data(lr_data)\n",
        "\n",
        "# Show first 5 rows of the dataframe to check\n",
        "lr_dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TdIYGdI58Cj2",
        "outputId": "7b17e61a-36ef-4561-d108-7dc3813b95e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Page total likes  Category  Post Month  Post Weekday  Post Hour  Paid  \\\n",
              "0          0.978371       0.0    0.909091      1.000000   0.454545   0.0   \n",
              "1          0.896850       0.0    0.636364      0.500000   0.363636   1.0   \n",
              "2          0.651409       1.0    0.363636      0.833333   0.227273   0.0   \n",
              "3          0.088185       1.0    0.000000      0.166667   0.272727   0.0   \n",
              "4          0.064111       1.0    0.000000      1.000000   0.409091   0.0   \n",
              "\n",
              "   Total Interactions  \n",
              "0            0.008683  \n",
              "1            0.005052  \n",
              "2            0.015630  \n",
              "3            0.017051  \n",
              "4            0.027787  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e09a792b-9160-4383-acd3-473214d8aa8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page total likes</th>\n",
              "      <th>Category</th>\n",
              "      <th>Post Month</th>\n",
              "      <th>Post Weekday</th>\n",
              "      <th>Post Hour</th>\n",
              "      <th>Paid</th>\n",
              "      <th>Total Interactions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.978371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.896850</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.651409</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.088185</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.064111</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e09a792b-9160-4383-acd3-473214d8aa8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e09a792b-9160-4383-acd3-473214d8aa8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e09a792b-9160-4383-acd3-473214d8aa8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data\n",
        "\n",
        "The data needs to be split into the training and testing sets for feature matrix $X$ and the target $Y$. 80% of the dataset will be used for training and 20% for testing."
      ],
      "metadata": {
        "id": "hxX-lpr488uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets x0 = 1 by appending a column of ones to account for the bias term.\n",
        "# Returns augmented matrix.\n",
        "def bias_trick(X):\n",
        "  x_0 = np.ones((len(X), 1), dtype=int)\n",
        "  X = np.hstack((x_0, X))\n",
        "  return X\n",
        "\n",
        "# Separates feature vectors and targets in the dataset. \n",
        "# Returns X as feature matrix and Y as vector of targets to predict.\n",
        "def separate_data(data):\n",
        "  X_no_bias = data[:,:-1]\n",
        "  X = bias_trick(X_no_bias)\n",
        "  Y = data[:,-1]\n",
        "  return X, Y\n",
        "\n",
        "# Splits the data into a training and testing set for X and Y. Returns the split data.\n",
        "def train_test_split(data, train_size=.80):\n",
        "    train = int(len(data)*train_size)\n",
        "    X, Y = separate_data(data)\n",
        "    X_train = X[:train]\n",
        "    y_train = Y[:train]\n",
        "    X_test = X[train:]\n",
        "    y_test = Y[train:]\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "VEoUhcPB9bOX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing the Model\n",
        "\n",
        "The Mean Squared Error (MSE) will be used as a way to measure the performance of the model. In order to do that, the derivative of the MSE will also be used to minimize the error.\n",
        "\n",
        "#### Mean Squared Error\n",
        "The model will compute $\\theta$ such that the MSE is minimized (the 1/2 factor makes the derivation easier). \n",
        "\n",
        "Let the MSE be a function of $\\theta, J(\\theta)$:\n",
        "\n",
        "$$J(\\theta) = \\frac{1}{2n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2$$\n",
        "\n",
        "where, $\\theta$ is the vector of weights computed to solve the equation:\n",
        "$$\\hat{y} = X \\theta = z$$\n",
        "\n",
        "In an expanded form, the same equation is:\n",
        "\n",
        "$$\\hat{y} = X \\theta =\n",
        "\\begin{bmatrix}\n",
        "    X_{1,0}\\theta_0 + X_{1,1}\\theta_1 + \\cdots + X_{1,d}\\theta_d  \\\\\n",
        "    X_{2,0}\\theta_0 + X_{2,1}\\theta_1 + \\cdots + X_{2,d}\\theta_d  \\\\\n",
        "    \\vdots   \\\\\n",
        "    X_{n,0}\\theta_0 + X_{n,1}\\theta_1 + \\cdots + X_{n,d}\\theta_d \n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "    z_1  \\\\\n",
        "    z_2  \\\\\n",
        "    \\vdots   \\\\\n",
        "    z_{n}\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "again where $X$ is the feature matrix, $\\theta$ is the weight vector, and $z$ and $\\hat{y}$ both represent the predicted value vector.\n",
        "\n",
        "#### Derivative of Mean Squared Error\n",
        "The derivative of the MSE is \n",
        "\n",
        "$$\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} ( \\hat{y_i} - y_i)x_{i,j}$$\n",
        "\n",
        "Now, combine MSE and derivative of MSE for a gradient descent algorithm to train the model."
      ],
      "metadata": {
        "id": "eG4kpufKLFOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean squared error bewteen the predicted values and target values. \n",
        "# Returns vector of the error values.\n",
        "def mse(y_pred, y_true):\n",
        "  return (1/(2*(len(y_pred))) * np.sum((y_pred - y_true)**2))\n",
        "\n",
        "# Calculate the derivative of the mean squared error. \n",
        "# Returns a vector of derivations of MSE.\n",
        "def mse_derivative(X,y,theta):\n",
        "  \n",
        "  # h is the predicted value vector\n",
        "  h = np.dot(X, theta)\n",
        "  return ((1/len(X)) * np.dot((h - y), X))\n",
        "\n",
        "'''\n",
        "Move one step with gradient descent. \n",
        "X is feature matrix, y is the target value vector,\n",
        "theta is the weight vector, alpha is the learning rate.\n",
        "Returns updated theta vector.\n",
        "'''\n",
        "def gradient_descent_step(X,y, theta, alpha):\n",
        "\n",
        "  # update theta vector\n",
        "  theta = theta - (alpha * mse_derivative(X, y, theta))\n",
        "  return theta\n",
        "\n",
        "# Combine all the pieces to calculate the linear regression. \n",
        "# Returns theta, train, and test error vectors.\n",
        "def linear_regression(data, num_epochs=30000, alpha=0.00005):\n",
        "    # Get training and testing set by calling train_test_split()\n",
        "    X_train, y_train, X_test, y_test = train_test_split(data)\n",
        "\n",
        "    # Record training and test errors in lists\n",
        "    train_errors= []\n",
        "    test_errors= []\n",
        "\n",
        "    # Define theta\n",
        "    theta = np.zeros((X_train.shape[1]))\n",
        "\n",
        "    # Carry out training loop\n",
        "    for i in range(num_epochs):\n",
        "        train_error = mse(np.dot(X_train, theta), y_train)\n",
        "        train_errors.append(train_error)\n",
        "\n",
        "        test_error = mse(np.dot(X_test, theta), y_test)\n",
        "        test_errors.append(test_error)\n",
        "\n",
        "        # Do gradient descent on the training set\n",
        "        theta = gradient_descent_step(X_train, y_train, theta, alpha)\n",
        "    return theta, train_errors, test_errors"
      ],
      "metadata": {
        "id": "sqjpzcBURJQZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and visualize results\n",
        "\n"
      ],
      "metadata": {
        "id": "cBk_RmEVUiMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carry out training task\n",
        "theta, train_errors, test_errors = linear_regression(lr_data)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot the training error and test error for different epochs (iterations of the\n",
        "# algorithm). Your plot be MSE error vs epochs.\n",
        "epochs = range(30000)\n",
        "a = plt.scatter(epochs, train_errors, color='blue')\n",
        "b = plt.scatter(epochs, test_errors, color='red')\n",
        "plt.title('MSE vs Epochs for Training and Testing')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend((a, b), ('Training', 'Testing'))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JIodqa_0UnTD",
        "outputId": "2d6d79a1-a81f-4b46-c6ba-6c0211d3c3b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZwV1Z3n8c/XRkCFAYPkQVDBSDSNDyC9GDWTaBwj5onJjMZ2dDSJu8bEh8SZrEpMZtGNmzibGWeckfFlRqJBDBgzJm3iaDTqamICNomJgJK0gILjA6IiREUaf/tHncbL5d7uruZWd9/u7/v1uq+uOnWq6pyq2/WrU6eqriICMzOz7tqlrwtgZmb1xYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4LABS9JsSTfVYDm7Sbpd0gZJ369F2WpB0r6SNklqqGXeviTpGElr+2jddbGN+gMHjjojabWkNyTtVZb+G0khaUIaHy/pB5JeSAe8pZI+naZNSHk3lX1OKbDcn5a0tcI69y5qnTV0EvAOYExEnLwzC5J0WkndX5P0Zun2yLOsiHgqIkZExNZa5u2PSg7qHZ+Q9MeS8T/twTJXS/qzjvF630a9aUhfF8B6ZBVwKvAvAJIOAXYvyzMP+C2wH7AZOAR4Z1me0RHRXmxRt/PLiHh/L66vVvYDft+TbSVpSOl8ETEfmJ+mHQPcFBHjq8zb4INYJiKeAkZ0jEsK4LCIaOu7Ug1ebnHUp3nAGSXjZwLfLcvz34AbIuKPEdEeEb+JiP/MuyJJp0hqLUu7UFJLGv6IpOWSNkp6WtKX864jLWe1pFlpWS9J+o6k4SXT/4ekNkkvSmopbalImizp7jTtOUlfKVn0UEnfTeVbJqmpZL6LU5k3Sloh6bgK5boM+DvglHRme5akXSR9VdKTkp5Pyx+V8ne05s6S9BRwb45tcIOkf5N0h6Q/AsdK+mhqTb4iaY2k2SX5O9Y1JI3fL+l/S/pFqtNPO1qmefKm6Wek+q2X9LXys/OycnenjGdKekpZC/jSkum7pXq/JGk52fc2F0nDJH0rLf85SddK2i1N20vSjyW9nL4fD6b9Nw/YF7g97deLitxGA05E+FNHH2A18GfACuC9QAOwluysOIAJKd89wC+AZmDfsmVMSHmHdGN9uwMbgUklaQ8DzWn4GeBP0/CewOFVlvNp4Odd1GspsA/wtlT2r6dpHwJeAA4HhpG1tB5I00amMvwtMDyNH5GmzQZeBz6SttM3gF+laQcCa4C9S7bJu6uUbTZZy6Bj/LNAG7A/2VnwfwDzyrbtd4E9gN06qfMxwNqS8RuADcDRZCd1w1OeQ9L4ocBzwJ9X2o/A/cATwHuA3dL4N3uQtxHYBLwfGAp8C9gC/Fkn9eiqjN9O6zmMrAX83jT9m8CDaZ/vQ/YdWFttm5WsM4AD0vBVQEtaxkjgduAbado3gGuBXdPnTwGV/i9V+7+o5TYaaB+3OOpXR6vjeOAx4Omy6SeT/UN+DVgl6RFJ5WdzL6QzsY7Pe8tXEhGvAj8iuzSGpEnAQWT/qJD9szRK+pOIeCkift1Jmd9Xtr4nyqb/a0SsiYgXgSs61gmcBsyNiF9HxGZgFnCksv6cjwHPRsQ/RMTrEbExIhaVLPPnEXFHZJd85pEduAC2kgWhRkm7RsTqiCgvTzWnAf8YESsjYlMqT3PHmWoyO7LW3mvdXGaHH0XELyLizVSf+yPi0TT+O+B7wAc7mf87EfH7tN5bgCk9yHsScHtE/Dwi3iBrcVV9qV03y3hZRLwWEb8lu4TasR8+BVwRES9GxBrg6k7KuwNJAs4GLkzL2Aj8H7ITJsi+n+8C9ouILRHxYKQjfzfVZBsNNA4c9Wse8FdkZ/Lll6lIB/FLImIyWcfuI8AP0z9ah70iYnTJ57Eq67qZtw7ifwX8MAUUgL8kO6N/UtL/k3RkJ2X+Vdn63l02fU3J8JNAx+WovdN4R902AeuBcWRnqZ0d8J8tGX4VGK6s36EN+BJZa+J5SQvU/Y767cqThoeQbedKdclju/kkHSHpPknrJG0AzgH2qjwrsGN9R1TL2EnevUvLkfb1+moL6WYZu7Uutt+u3TGWrFW8pOOEBLgzpQP8X7LW4U8lrZR0Sc7l12QbDTQOHHUqIp4k6yT/CNmlks7yvkDWlN6brDmf193AWElTyALIzSXLfjgiZgJvB35IdlbWU/uUDO8L/Fca/i+yS3EASNoDGEPWylpDdskot4i4ObLO+o7LfFd2c9btypPK2k52iWbb4ntSpgrz3UzWutsnIkaRXXbRDnPV1jPAtg771F8wppP8O1PGZ9hxv+fxAvAaMLnkhGRURIwASC3Qv42I/YFPAH+jt/qydqaFkHcbDSgOHPXtLOBDEfHH8gmSrpR0sKQhkkYCnwfaIiL3WVFEbAG+T3b29jayQIKkocpuLx2V8rwCvLkT9TlX2W3EbwMuBRam9O8Bn5E0RdIwsksRiyJiNfBj4F2SvpQ6SUdKOqKrFUk6UNKH0vJeJzv4dLfs3wMulDRR0ohUnoVRzB1qI4EXI+J1SdPJWnxFuxX4uKSjJA0la5V1Fgh2poy3ALMk7SlpPHB+noJGxJtk/SdXSXo7gKRxkk5Iwx+TdEBqaW8gu0TZsZ+fo4cnHeTfRgOKA0cdi4gnIqK1yuTdgduAl4GVZGfInyjL87K2vzf+bzpZ3c1knfLfLztA/jWwWtIrZJcoTutkGUdqx+c4SvtdbgZ+msr7BPD1VM97yPpqfkB2pvdu0jXsdE37eODjZJcV/gAc20kZOgwj65h9Ic33drK+iu6YS3ap8AGyVt/r5Dzg5fAF4HJJG8muo+9Mi65bImIZWX0WkG3vTcDzZJ3atS7jZWSXp1aR7ft5PSjyxWSXo36Vvof3kN38ADApjW8CfgnMiYj70rRvAF9Nl7hy3Q3Yg200oHTcXWDWpyStBv57ChLWj6RW1ctkd9at6uvy9EeDbRu5xWFmO5D0cUm7p/6kbwGPkt2+aslg3kYOHGZWyUyymwD+i+xyT3PO21gHg0G7jQq9VCVpBvDPZA9f/XtEfLNs+jCyW0mnkd3Kdkrq8ETSLLLO363ABRFxl6QDeavDFLKOrb+LiH8qrBJmZradwgKHsjdM/p6s43It2dPGp0bE8pI8XwAOjYhzJDUDn4yIUyQ1kt25Mp3sFtJ7gPdEyXt70vKfJntKOO+932Zm1kNFvuRwOtntnysBJC0ga9otL8kzk+w2Nshub/vXdNvcTGBBekp4laS2tLxflsx7HPBEd4LGXnvtFRMmTNi52piZDSJLlix5ISLGVppWZOAYx/ZPhK4Fyu+v35YnItrTU6djUvqvyuYdVzZvM1mrpCJJZ5O9ioB9992X1tZqd62amVk5SVVPyuuyczw9cPMJsofSKoqI6yKiKSKaxo6tGDTNzKwHigwcT7P9qwTGs+OL+LblSS+IG0XWSd7VvCcCv46I0lc8mJlZLygycDwMTEqvZRhKdmmppSxPC9lvSUD2tsl70+1sLWRvGx0maSLZrW6LS+Y7lU4uU5mZWXEK6+NIfRbnAXeR3Y47NyKWSbocaI2IFuB6YF7q/H6Rt14jsUzSLWQd6e3AuR13VKWHbY4HPldU2c2s/m3ZsoW1a9fy+uuv93VR+rXhw4czfvx4dt11127PMyheOdLU1BTuHDcbXFatWsXIkSMZM2YM2/+agHWICNavX8/GjRuZOHHidtMkLYmIpkrz1WXneK+QdvyYWd14/fXXHTS6IIkxY8bkbpU5cFRS7YvmAGJWVxw0utaTbeTA0RMOIGY2iDlw7AwHEDOrYv369UyZMoUpU6bwzne+k3Hjxm0bf+ONNzqdt7W1lQsuuKDLdRx11FG1Km4uRT45PnhIMHo0vPRSX5fEzPqJMWPG8MgjjwAwe/ZsRowYwZe//NbvRbW3tzNkSOVDcFNTE01NFfult/PQQw/VprA5ucVRKy+/nAWQhoa+LomZ9cD8+TBhAuyyS/Z3/vzar+PTn/4055xzDkcccQQXXXQRixcv5sgjj2Tq1KkcddRRrFixAoD777+fj33sY0AWdD772c9yzDHHsP/++3P11VdvW96IESO25T/mmGM46aSTOOiggzjttNPouGP2jjvu4KCDDmLatGlccMEF25a7M9ziqLU333zr8tUguNXZbCCYPx/OPhtefTUbf/LJbBzgtM5+DLkH1q5dy0MPPURDQwOvvPIKDz74IEOGDOGee+7hK1/5Cj/4wQ92mOfxxx/nvvvuY+PGjRx44IF8/vOf3+G5i9/85jcsW7aMvffem6OPPppf/OIXNDU18bnPfY4HHniAiRMncuqpp9akDm5xVFKrA777QMzqwqWXvhU0Orz6apZeayeffDIN6crEhg0bOPnkkzn44IO58MILWbZsWcV5PvrRjzJs2DD22msv3v72t/Pcczu+bWn69OmMHz+eXXbZhSlTprB69Woef/xx9t9//23PaDhwFC3CAcRskHjqqXzpO2OPPfbYNvy1r32NY489lqVLl3L77bdXfZ5i2LBh24YbGhpob2/vUZ5aceDoShEBxEHErF/Zd9986bWyYcMGxo3LfjHihhtuqPnyDzzwQFauXMnq1asBWLhwYeczdJMDR3fVMoCAA4hZP3LFFbD77tun7b57ll6kiy66iFmzZjF16tRCWgi77bYbc+bMYcaMGUybNo2RI0cyatSonV6u31XVU0Uc9AfBvjDrLY899hjvfe97u51//vysT+Opp7KWxhVX1L5jvC9s2rSJESNGEBGce+65TJo0iQsvvHC7PJW2VWfvqvJdVT3VcZCvZQApXZaDiFmvOu20gREoyn3729/mxhtv5I033mDq1Kl87nM7/2JxB46dVUQAKV+eg4iZ9dCFF164QwtjZzlw1EpRAaR8mQ4iZtbHHDhqrcgAUr5cBxEz6wMOHEUpPaj3RhApX6eZWUEcOHpD0a2QDg4kZtYLHDh6U2+0Qko5kJj1mfXr13PccccB8Oyzz9LQ0MDYsWMBWLx4MUOHDu10/vvvv5+hQ4due3X6tddey+67784ZZ5xRbMG7wYGjr/R2EKm2HgcTs0J09Vr1rtx///2MGDFiW+A455xzCilnT/jJ8f6g46n0vjiI+7fVzTK98F71JUuW8MEPfpBp06Zxwgkn8MwzzwBw9dVX09jYyKGHHkpzczOrV6/m2muv5aqrrmLKlCk8+OCDzJ49m29961sAHHPMMVx88cVMnz6d97znPTz44IMAvPrqq3zqU5+isbGRT37ykxxxxBHU/OFn3OLof/qiJVKu2nrdOrGBqhfeqx4RnH/++fzoRz9i7NixLFy4kEsvvZS5c+fyzW9+k1WrVjFs2DBefvllRo8ezTnnnLNdK+VnP/vZdstrb29n8eLF3HHHHVx22WXcc889zJkzhz333JPly5ezdOlSpkyZUpOyl3OLoz8rbYk0NvZ1aSq3TtxCsYGgF96rvnnzZpYuXcrxxx/PlClT+PrXv87atWsBOPTQQznttNO46aabqv4qYLm/+Iu/AGDatGnbXmL485//nObmZgAOPvhgDj300JqVv5RbHPWi/D39/emA3VVZ3FKx/q4X3qseEUyePJlf/vKXO0z7yU9+wgMPPMDtt9/OFVdcwaOPPtrl8jpeo170K9QrKbTFIWmGpBWS2iRdUmH6MEkL0/RFkiaUTJuV0ldIOqEkfbSkWyU9LukxSUcWWYd+q7Q10t8PzNVaKm6xWH/RC+9VHzZsGOvWrdsWOLZs2cKyZct48803WbNmDcceeyxXXnklGzZsYNOmTYwcOZKNGzfmWsfRRx/NLbfcAsDy5cu7FYB6orDAIakBuAY4EWgETpVUfr3lLOCliDgAuAq4Ms3bCDQDk4EZwJy0PIB/Bu6MiIOAw4DHiqpDXSkPJKNH93WJuq+rwOIAY0Xrhfeq77LLLtx6661cfPHFHHbYYUyZMoWHHnqIrVu3cvrpp3PIIYcwdepULrjgAkaPHs3HP/5xbrvttm2d493xhS98gXXr1tHY2MhXv/pVJk+eXJPXqO8gIgr5AEcCd5WMzwJmleW5CzgyDQ8BXgBUnrcjHzAKWEV6HXx3P9OmTQuL8tAysD826C1fvjzfDDfdFLHffhFS9vemm4ooVqHa29vjtddei4iItra2mDBhQmzevLnL+SptK6A1qhxTi+zjGAesKRlfCxxRLU9EtEvaAIxJ6b8qm3cc8BqwDviOpMOAJcAXI+KPhdRgoKl0SWugnsnvTL36+6U/K8YAeK/6q6++yrHHHsuWLVuICObMmdPlg4Y9UW+d40OAw4HzI2KRpH8GLgG+Vp5R0tnA2QD7Fv37j/Ws2kFyoAaU7qhl3R2ErBeNHDmykOc2yhXZOf40sE/J+PiUVjGPpCFkl6LWdzLvWmBtRCxK6beSBZIdRMR1EdEUEU0dj/lbDtUuAlk+3e2/2dmPVRT+znapJ9uoyMDxMDBJ0kRJQ8k6u1vK8rQAZ6bhk4B707W1FqA53XU1EZgELI6IZ4E1kg5M8xwHLC+wDlauq94F6xu9FaDqKMANHz6c9evXO3h0IiJYv349w4cPzzVfYZeqUp/FeWQd2w3A3IhYJulysk6XFuB6YJ6kNuBFsuBCyncLWVBoB86NiK1p0ecD81MwWgl8pqg6WA909U/qs+PBrRf3//g992Tt7NmsO+CA7DUiA9l++/V41uHDhzN+/Phc82gwROOmpqbojet+VkMOMGa1lfNYL2lJRDRVmlZvneM2WOT5kjvImHVNqtnlZAcOq38788/goGOWmwOHDW61vFTrIGSDhAOHWa30Vn+hA5T1MQcOs3pTLze0OMANWA4cZlaMeglw9aanAbmG+8OBw8ysnvSDgDzAn4oxM7Nac+AwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DAzs1wcOMzMLBcHDjMzy8WBw8zMcnHgMDOzXBw4zMwsFwcOMzPLxYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DAzs1wKDRySZkhaIalN0iUVpg+TtDBNXyRpQsm0WSl9haQTStJXS3pU0iOSWossv5mZ7aiw3xyX1ABcAxwPrAUeltQSEctLsp0FvBQRB0hqBq4ETpHUCDQDk4G9gXskvScitqb5jo2IF4oqu5mZVVdki2M60BYRKyPiDWABMLMsz0zgxjR8K3CcJKX0BRGxOSJWAW1peWZm1seKDBzjgDUl42tTWsU8EdEObADGdDFvAD+VtETS2dVWLulsSa2SWtetW7dTFTEzs7fUY+f4+yPicOBE4FxJH6iUKSKui4imiGgaO3Zs75bQzGwAKzJwPA3sUzI+PqVVzCNpCDAKWN/ZvBHR8fd54DZ8CcvMrFcVGTgeBiZJmihpKFlnd0tZnhbgzDR8EnBvRERKb053XU0EJgGLJe0haSSApD2ADwNLC6yDmZmVKeyuqohol3QecBfQAMyNiGWSLgdaI6IFuB6YJ6kNeJEsuJDy3QIsB9qBcyNiq6R3ALdl/ecMAW6OiDuLqoOZme1I2Qn+wNbU1BStrX7kw8ysuyQtiYimStPqsXPczMz6kAOHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLg4cZmaWiwOHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLoUGDkkzJK2Q1CbpkgrTh0lamKYvkjShZNqslL5C0gll8zVI+o2kHxdZfjMz21FhgUNSA3ANcCLQCJwqqbEs21nASxFxAHAVcGWatxFoBiYDM4A5aXkdvgg8VlTZzcysuiJbHNOBtohYGRFvAAuAmWV5ZgI3puFbgeMkKaUviIjNEbEKaEvLQ9J44KPAvxdYdjMzq6LTwCHp9JLho8umndfFsscBa0rG16a0inkioh3YAIzpYt5/Ai4C3uyi7GdLapXUum7dui6KamZm3dVVi+NvSob/pWzaZ2tcli5J+hjwfEQs6SpvRFwXEU0R0TR27NheKJ2Z2eDQVeBQleFK4+WeBvYpGR+f0irmkTQEGAWs72Teo4FPSFpNdunrQ5Ju6qIcZmZWQ10FjqgyXGm83MPAJEkTJQ0l6+xuKcvTApyZhk8C7o2ISOnN6a6ricAkYHFEzIqI8RExIS3v3og4HTMz6zVDuph+kKTfkbUu3p2GSeP7dzZjRLSnfpC7gAZgbkQsk3Q50BoRLcD1wDxJbcCLZMGAlO8WYDnQDpwbEVt7VkUzM6slZSf4VSZK+3U2c0Q8WfMSFaCpqSlaW1v7uhhmZnVD0pKIaKo0rdMWR3lgkDQG+ADwVHc6qM3MbODp6nbcH0s6OA2/C1hKdjfVPElf6oXymZlZP9NV5/jEiFiahj8D3B0RHweOoA9uxzUzs77XVeDYUjJ8HHAHQERspIsH8MzMbGDq6q6qNZLOJ3ty+3DgTgBJuwG7Flw2MzPrh7pqcZxF9qLBTwOnRMTLKf19wHcKLJeZmfVTXd1V9TxwToX0+4D7iiqUmZn1X50GDknlT3pvJyI+UdvimJlZf9dVH8eRZG+p/R6wiK7fT2VmZgNcV4HjncDxwKnAXwE/Ab4XEcuKLpiZmfVPnXaOR8TWiLgzIs4k6xBvA+7vxm9xmJnZANVViwNJw8h+ce9UYAJwNXBbscUyM7P+qqvO8e8CB5M9+HdZyVPkZmY2SHXV4jgd+CPwReCC7OfAgayTPCLiTwosm5mZ9UNdPcfR1QOCZmY2yDgwmJlZLg4cZmaWiwOHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS6FBg5JMyStkNQm6ZIK04dJWpimL5I0oWTarJS+QtIJKW24pMWSfitpmaTLiiy/mZntqLDAIakBuAY4EWgETpXUWJbtLOCliDgAuAq4Ms3bCDST/d75DGBOWt5m4EMRcRgwBZgh6X1F1cHMzHZUZItjOtAWESsj4g1gATCzLM9M4MY0fCtwnLI3Kc4EFkTE5ohYRfY7INMjsynl3zV9osA6mJlZmSIDxziyn53tsDalVcwTEe3ABmBMZ/NKapD0CPA8cHdELKq0cklnS2qV1Lpu3boaVMfMzKAOO8fTrxJOAcYD0yUdXCXfdRHRFBFNY8eO7d1CmpkNYEUGjqeBfUrGx6e0inkkDQFGAeu7M29EvAzcR9YHYmZmvaTIwPEwMEnSRElDyTq7W8rytABnpuGTgHsjIlJ6c7rraiIwCVgsaayk0QCSdgOOBx4vsA5mZlamy98c76mIaJd0HnAX0ADMjYhlki4HWiOiBbgemCepDXiRLLiQ8t0CLAfagXMjYqukdwE3pjusdgFuiYgfF1UHMzPbkbIT/IGtqakpWltb+7oYZmZ1Q9KSiGiqNK3uOsfNzKxvOXCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLg4cZmaWiwOHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLg4cZmaWiwOHmZnl4sBhZma5FBo4JM2QtEJSm6RLKkwfJmlhmr5I0oSSabNS+gpJJ6S0fSTdJ2m5pGWSvlhk+c3MbEeFBQ5JDcA1wIlAI3CqpMaybGcBL0XEAcBVwJVp3kagGZgMzADmpOW1A38bEY3A+4BzKyzTzMwKVGSLYzrQFhErI+INYAEwsyzPTODGNHwrcJwkpfQFEbE5IlYBbcD0iHgmIn4NEBEbgceAcQXWwczMyhQZOMYBa0rG17LjQX5bnohoBzYAY7ozb7qsNRVYVGnlks6W1Cqpdd26dT2uhJmZba8uO8cljQB+AHwpIl6plCcirouIpohoGjt2bO8W0MxsACsycDwN7FMyPj6lVcwjaQgwCljf2bySdiULGvMj4j8KKbmZmVVVZOB4GJgkaaKkoWSd3S1leVqAM9PwScC9EREpvTnddTURmAQsTv0f1wOPRcQ/Flh2MzOrYkhRC46IdknnAXcBDcDciFgm6XKgNSJayILAPEltwItkwYWU7xZgOdmdVOdGxFZJ7wf+GnhU0iNpVV+JiDuKqoeZmW1P2Qn+wNbU1BStra19XQwzs7ohaUlENFWaVped42Zm1nccOMzMLBcHDjMzy8WBw8zMcnHgMDOzXBw4zMwsFwcOMzPLxYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DAzs1wcOMzMLBcHjiqkHT/z5/d1qczM+p4DRwVS5fTTT38riJiZDVaF/QLgQFcaPAbBb2GZmW3jwFEDDiJmNpg4cNSYg4iZDXQOHAVyEDGzgciBo4KI2neAly/PgcTM6pUDRxVFBI9SDiRmVq8cODrRcTDvjdtvK63DwcTM+iMHjm4oPYD35jMcDiZm1h8V+gCgpBmSVkhqk3RJhenDJC1M0xdJmlAybVZKXyHphJL0uZKel7S0yLJXE/HWpy9UeqLdDySaWW8qLHBIagCuAU4EGoFTJTWWZTsLeCkiDgCuAq5M8zYCzcBkYAYwJy0P4IaU1uf6OoiUqhZQHFTMrNaKbHFMB9oiYmVEvAEsAGaW5ZkJ3JiGbwWOk6SUviAiNkfEKqAtLY+IeAB4scBy90h/CiLlOgsqDi5mlleRgWMcsKZkfG1Kq5gnItqBDcCYbs7bKUlnS2qV1Lpu3bqcRd85pUGkPwaSSroTXBxgzAwG8EsOI+K6iGiKiKaxY8f2cVnqL5BU090A46BjNnAVeVfV08A+JePjU1qlPGslDQFGAeu7OW/dqhQ8BsOBteg61ntQNqsXRbY4HgYmSZooaShZZ3dLWZ4W4Mw0fBJwb0RESm9Od11NBCYBiwssa58rb5X4IJjfzrSG6ukzdGhfb2kb7AprcUREu6TzgLuABmBuRCyTdDnQGhEtwPXAPEltZB3ezWneZZJuAZYD7cC5EbEVQNL3gGOAvSStBf5XRFxfVD36UrXgMRhaJ1bdli3+Dlh+tTwZVQyCU9umpqZobW3t62L0Ch9QzIE548EAAAcxSURBVKyaPId7SUsioqnSND85PsB054vh4GJmO8OBYxDKd9ZRXDnMrD45cFinenol0wHHbOBy4LBCFN115sBk1nccOKwuDYJ7OrZxkLRaqOX/jAOHWT83mIKk1YcB+8oRMzMrhgOHmZnl4sBhZma5OHCYmVkuDhxmZpbLoHhXlaR1wJM9nH0v4IUaFqcvDZS6DJR6gOvSHw2UesDO1WW/iKj4Y0aDInDsDEmt1V70VW8GSl0GSj3AdemPBko9oLi6+FKVmZnl4sBhZma5OHB07bq+LkANDZS6DJR6gOvSHw2UekBBdXEfh5mZ5eIWh5mZ5eLAYWZmuThwVCFphqQVktokXdLX5alG0mpJj0p6RFJrSnubpLsl/SH93TOlS9LVqU6/k3R4yXLOTPn/IOnMXir7XEnPS1paklazskualrZNW5q3kBeUV6nHbElPp/3yiKSPlEyblcq0QtIJJekVv3OSJkpalNIXShpaRD3SuvaRdJ+k5ZKWSfpiSq+r/dJJPepuv0gaLmmxpN+mulzW2folDUvjbWn6hJ7WsaqI8KfsAzQATwD7A0OB3wKNfV2uKmVdDexVlvb3wCVp+BLgyjT8EeA/AQHvAxal9LcBK9PfPdPwnr1Q9g8AhwNLiyg7sDjlVZr3xF6sx2zgyxXyNqbv0zBgYvqeNXT2nQNuAZrT8LXA5wvcJ+8CDk/DI4HfpzLX1X7ppB51t1/SdhqRhncFFqXtV3H9wBeAa9NwM7Cwp3Ws9nGLo7LpQFtErIyIN4AFwMw+LlMeM4Eb0/CNwJ+XpH83Mr8CRkt6F3ACcHdEvBgRLwF3AzOKLmREPAC8WETZ07Q/iYhfRfZf892SZfVGPaqZCSyIiM0RsQpoI/u+VfzOpbPxDwG3pvlLt0nNRcQzEfHrNLwReAwYR53tl07qUU2/3S9p225Ko7umT3Sy/tJ9dStwXCpvrjp2ViYHjsrGAWtKxtfS+ZeuLwXwU0lLJJ2d0t4REc+k4WeBd6ThavXqT/WtVdnHpeHy9N50Xrp8M7fj0g756zEGeDki2svSC5cucUwlO8Ot2/1SVg+ow/0iqUHSI8DzZEH4iU7Wv63MafqGVN6a/f87cNS/90fE4cCJwLmSPlA6MZ3V1eU91/VcduDfgHcDU4BngH/o2+LkI2kE8APgSxHxSum0etovFepRl/slIrZGxBRgPFkL4aC+LI8DR2VPA/uUjI9Paf1ORDyd/j4P3Eb2pXouXRIg/X0+Za9Wr/5U31qV/ek0XJ7eKyLiufTP/ibwbbL9AvnrsZ7s8s+QsvTCSNqV7GA7PyL+IyXX3X6pVI963i8AEfEycB9wZCfr31bmNH1UKm/N/v8dOCp7GJiU7loYStbB1NLHZdqBpD0kjewYBj4MLCUra8ddLGcCP0rDLcAZ6U6Y9wEb0uWHu4APS9ozNd0/nNL6Qk3Knqa9Iul96fruGSXLKlzHQTb5JNl+6ahHc7rzZSIwiayzuOJ3Lp3d3weclOYv3SZFlFvA9cBjEfGPJZPqar9Uq0c97hdJYyWNTsO7AceT9dlUW3/pvjoJuDeVN1cdOy1Ure8AGCgfsrtFfk92LfHSvi5PlTLuT3YHxG+BZR3lJLue+TPgD8A9wNtSuoBrUp0eBZpKlvVZss6yNuAzvVT+75FdLthCdl31rFqWHWgiOzA8Afwr6U0JvVSPeamcv0v/hO8qyX9pKtMKSu4oqvadS/t5carf94FhBe6T95Ndhvod8Ej6fKTe9ksn9ai7/QIcCvwmlXkp8HedrR8Ynsbb0vT9e1rHah+/csTMzHLxpSozM8vFgcPMzHJx4DAzs1wcOMzMLBcHDjMzy8WBw6yHJG3VW29ZfaRbbxXt/rInqORtu2b9yZCus5hZFa9F9hoIs0HFLQ6zGlP2Gyl/r+w3JxZLOiClT5B0b3rB3s8k7ZvS3yHpNmW/t/BbSUelRTVI+ray32D4aXpqGEkXKPudid9JWtBH1bRBzIHDrOd2K7tUdUrJtA0RcQjZk9H/lNL+BbgxIg4F5gNXp/Srgf8XEYeR/a7HspQ+CbgmIiYDLwN/mdIvAaam5ZxTVOXMqvGT42Y9JGlTRIyokL4a+FBErEwv2ns2IsZIeoHsFRdbUvozEbGXpHXA+IjYXLKMCWS/ZzEpjV8M7BoRX5d0J7AJ+CHww3jrtxrMeoVbHGbFiCrDeWwuGd7KW32SHyV7P9ThwMMlb0g16xUOHGbFOKXk7y/T8ENkbx4FOA14MA3/DPg8bPvBnlHVFippF2CfiLgPuJjsldk7tHrMiuQzFbOe2y39KluHOyOi45bcPSX9jqzVcGpKOx/4jqT/CawDPpPSvwhcJ+ksspbF58netltJA3BTCi4Cro7sNxrMeo37OMxqLPVxNEXEC31dFrMi+FKVmZnl4haHmZnl4haHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXy/wGMDcg+txoNSgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "The model did well simply based on the graph. The training MSE seems to end up around 0.001 and the testing MSE seems to end around 0.0006 after 30000 iterations. The model seems to be well optimized after about 10000 iterations, which is 1/3 of the total epochs."
      ],
      "metadata": {
        "id": "bfOmcNJXUqqB"
      }
    }
  ]
}